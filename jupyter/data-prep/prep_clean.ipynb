{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "956a5213-80e9-4452-8e43-b1c90867ead3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Preprocess data\n",
    "\n",
    "def preprocess_bike_df(df):\n",
    "    # Date string to datetime object\n",
    "    df['dteday'] = pd.to_datetime(df['dteday'])\n",
    "\n",
    "    # Calculate day of the year (1-365)\n",
    "    df['day_enumerated'] = df['dteday'].dt.dayofyear\n",
    "\n",
    "    # Adjust day_of_year for second year to continue counting (e.g. Jan 1, 2012 would be 366 instead of 1)\n",
    "    df.loc[df['dteday'].dt.year == 2012, 'day_enumerated'] += 365\n",
    "\n",
    "    # Normalize to [0, 4pi]\n",
    "    df['date_scaled'] = (df['day_enumerated'] / 731) * 4 * np.pi\n",
    "\n",
    "    # Encode cyclic nature\n",
    "    df['date_sin'] = np.sin(df['date_scaled'])\n",
    "    df['date_cos'] = np.cos(df['date_scaled'])\n",
    "\n",
    "    # Normalize to [0, 2pi]\n",
    "    df['hour_scaled'] = (df['hr'] / 24) * 2 * np.pi\n",
    "\n",
    "    # Encode cyclic nature\n",
    "    df['hour_sin'] = np.sin(df['hour_scaled'])\n",
    "    df['hour_cos'] = np.cos(df['hour_scaled'])\n",
    "\n",
    "    df['weekday'] = df['weekday'].astype(str)\n",
    "    weekday_dummies = pd.get_dummies(df['weekday'], prefix='weekday')\n",
    "\n",
    "    # Concatenate the original DataFrame with the dummy DataFrame\n",
    "    df = pd.concat([df, weekday_dummies], axis=1)\n",
    "    \n",
    "    # Standardize features and target\n",
    "    scaler = StandardScaler()\n",
    "    standardized = [\"temp\", \"atemp\", \"hum\", \"windspeed\", \"cnt\"]\n",
    "    df.loc[:, standardized] = scaler.fit_transform(df[standardized])    \n",
    "    \n",
    "    return df[[\n",
    "        \"yr\", \"date_cos\", \"date_sin\", \"hour_cos\", \"hour_sin\",\n",
    "        \"weekday_0\", \"weekday_1\", \"weekday_2\", \"weekday_3\", \"weekday_4\", \"weekday_5\", \"weekday_6\",\n",
    "        \"holiday\", \"workingday\", \"weathersit\", \"temp\", \"atemp\", \"hum\", \"windspeed\", \"cnt\"\n",
    "    ]]\n",
    "\n",
    "\n",
    "def homogeneous_client_slices(df):\n",
    "    n_tot = len(df)\n",
    "    n_clients = 8\n",
    "    ix = np.random.permutation(n_tot)\n",
    "    n_c = n_tot // n_clients\n",
    "    \n",
    "    client_slices = []\n",
    "    for client in range(n_clients):\n",
    "        c_slice = np.zeros(n_tot, dtype=bool)\n",
    "        c_slice[ix[client * n_c : (client + 1) * n_c]] = True\n",
    "        client_slices.append(c_slice)\n",
    "        \n",
    "    return client_slices\n",
    "\n",
    "\n",
    "def heterogeneous_client_slices(df):\n",
    "    n_tot = len(df)\n",
    "    n_clients = 8\n",
    "    n_c = n_tot // n_clients\n",
    "    \n",
    "    client_slices = []\n",
    "    for client in range(n_clients):\n",
    "        c_slice = np.zeros(n_tot, dtype=bool)\n",
    "        c_slice[client * n_c : (client + 1) * n_c] = True\n",
    "        client_slices.append(c_slice)\n",
    "        \n",
    "    return client_slices\n",
    "\n",
    "\n",
    "def client_split_df(df, client_slices):\n",
    "    client_dfs = []\n",
    "    for c_slice in client_slices:\n",
    "        client_dfs.append(df[c_slice].sample(frac=1))\n",
    "        \n",
    "    return client_dfs\n",
    "\n",
    "\n",
    "def client_dfs_to_tensor(client_dfs):\n",
    "    client_tensors = [torch.tensor(client_df.values) for client_df in client_dfs]\n",
    "    return torch.stack(client_tensors)\n",
    "\n",
    "\n",
    "def dev_test_split(data):\n",
    "    n_test = 252\n",
    "    devdata = data[:, None, :-n_test, :]\n",
    "    testdata = data[:, None, -n_test:, :]\n",
    "    return devdata, testdata\n",
    "\n",
    "\n",
    "def train_val_split(data):\n",
    "    n_cp = 160\n",
    "    n_cp_val = 2\n",
    "    n_cols = 20\n",
    "    cp_data = data.reshape(8, n_cp, -1, n_cols)\n",
    "    cp_traindata = cp_data[:, :, :-n_cp_val, :]\n",
    "    cp_valdata = cp_data[:, :n_cp/2, -n_cp_val:, :]\n",
    "    return cp_traindata, cp_valdata\n",
    "\n",
    "\n",
    "def X_y_split(data):\n",
    "    X = data[:, :, :, :-1]\n",
    "    y = data[:, :, :, -1]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def static_dataset(X, y):\n",
    "    return X.reshape((8, -1, 19)), y.reshape((8, -1))\n",
    "\n",
    "\n",
    "def get_clean_data(heterogeneous=True, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    df = pd.read_csv(\"/proj/fair-ai/fair-fl/data/bike.csv\")\n",
    "    df_Xy = preprocess_bike_df(df)\n",
    "    client_slices = heterogeneous_client_slices(df) if heterogeneous else homogeneous_client_slices(df)\n",
    "    client_dfs = client_split_df(df_Xy, client_slices)\n",
    "    data = client_dfs_to_tensor(client_dfs)\n",
    "    devdata, testdata = dev_test_split(data)\n",
    "    traindata, valdata = train_val_split(devdata)\n",
    "    \n",
    "    return X_y_split(traindata), static_dataset(*X_y_split(valdata)), static_dataset(*X_y_split(testdata))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
