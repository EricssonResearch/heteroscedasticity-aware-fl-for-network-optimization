{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d67ffe-d2c7-4e03-81ff-fef390a72060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import sem\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Summarizing experiments\n",
    "\n",
    "class Experiment:\n",
    "    def __init__(self, experiment_data):\n",
    "        (self.algorithm,\n",
    "         self.date, \n",
    "         self.sim,\n",
    "         self.params, \n",
    "         self.sim_info,\n",
    "         self.n_clients, \n",
    "         self.n_rounds,\n",
    "         self.n_checkpoints,\n",
    "         self.n_cp_train_samps,\n",
    "         self.n_cp_val_samps,\n",
    "         self.client_mse,\n",
    "         self.client_clean_mse,\n",
    "         self.client_epistemic_mse,\n",
    "         self.client_aleatoric_var,\n",
    "         self.avg_mse, \n",
    "         self.var_mse,\n",
    "         self.avg_clean_mse,\n",
    "         self.var_clean_mse,\n",
    "         self.avg_epistemic_mse,\n",
    "         self.var_epistemic_mse) = self._dict_to_experiment(experiment_data)\n",
    "\n",
    "    def _dict_to_experiment(self, experiment_data):\n",
    "        algorithm = experiment_data['params']['algorithm']\n",
    "        date = datetime.strptime(experiment_data['date'], \"%Y-%m-%d_%H:%M:%S\")\n",
    "        sim = experiment_data['params']['sim']\n",
    "        params = experiment_data['params']\n",
    "        sim_info = experiment_data['simulation']\n",
    "        \n",
    "        n_clients = int(params['min_available_clients'])\n",
    "        n_rounds = int(params['n_rounds'])\n",
    "        \n",
    "        n_checkpoints = int(sim_info['n_checkpoints'])\n",
    "        n_cp_train_samps = int(sim_info['n_checkpoint_train_samples'])\n",
    "        n_cp_val_samps = int(sim_info['n_checkpoint_val_samples'])\n",
    "        \n",
    "        client_mse = np.zeros((n_rounds, n_clients))\n",
    "        for round_num, mse_dict in experiment_data['results']['metrics_distributed']['client_mse']:\n",
    "            client_mse[round_num - 1] = np.array([mse_dict[str(i)] for i in range(n_clients)])\n",
    "            \n",
    "        client_clean_mse = np.zeros((n_rounds, n_clients))\n",
    "        for round_num, clean_mse_dict in experiment_data['results']['metrics_distributed']['client_clean_mse']:\n",
    "            client_clean_mse[round_num - 1] = np.array([clean_mse_dict[str(i)] for i in range(n_clients)])\n",
    "            \n",
    "        client_aleatoric_var = np.zeros((n_rounds, n_clients))\n",
    "        for round_num, aleatoric_var_dict in experiment_data['results']['metrics_distributed']['client_noise_var']:\n",
    "            client_aleatoric_var[round_num - 1] = np.array([aleatoric_var_dict[str(i)] for i in range(n_clients)])\n",
    "            \n",
    "        client_epistemic_mse = client_mse - client_aleatoric_var\n",
    "            \n",
    "        avg_mse = client_mse.mean(axis=1)\n",
    "        var_mse = client_mse.var(axis=1)\n",
    "        avg_clean_mse = client_clean_mse.mean(axis=1)\n",
    "        var_clean_mse = client_clean_mse.var(axis=1)\n",
    "        avg_epistemic_mse = client_epistemic_mse.mean(axis=1)\n",
    "        var_epistemic_mse = client_epistemic_mse.var(axis=1)\n",
    "        \n",
    "        return (algorithm, date, sim, params, sim_info, n_clients, n_rounds, n_checkpoints,\n",
    "                n_cp_train_samps, n_cp_val_samps, client_mse, client_clean_mse, client_epistemic_mse, client_aleatoric_var, \n",
    "                avg_mse, var_mse, avg_clean_mse, var_clean_mse, avg_epistemic_mse, var_epistemic_mse)\n",
    "\n",
    "    def __str__(self):\n",
    "        return \\\n",
    "f\"\"\"\\\n",
    "Experiment {self.date}\n",
    "\n",
    "algorithm:\\t\\t{self.algorithm}\n",
    "data:\\t\\t\\t{self.sim}\n",
    "n_clients:\\t\\t{self.n_clients}\n",
    "n_rounds:\\t\\t{self.n_rounds}\n",
    "n_checkpoints:\\t\\t{self.n_checkpoints}\n",
    "n_cp_train_samps:\\t{self.n_cp_train_samps}\n",
    "n_cp_val_samps:\\t\\t{self.n_cp_val_samps}\n",
    "avg_mse:\\t\\t\\t{self.avg_mse[-1]:.5g}\n",
    "var_mse:\\t\\t\\t{self.var_mse[-1]:.5g}\n",
    "    \n",
    "params: {self.params}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_experiment(select=\"all\", directory=\"/proj/fair-ai/fair-fl/out\"):\n",
    "    # Find all JSON files in the directory\n",
    "    json_files = glob(os.path.join(directory, \"*.json\"))\n",
    "\n",
    "    # Extract the datetimes and file paths for each file\n",
    "    datetime_files = []\n",
    "    for json_file in json_files:\n",
    "        try:\n",
    "            datetime_str = re.search(r\"experiment-(\\d{4}_\\d{2}_\\d{2}-\\d{2}_\\d{2}_\\d{2})\", json_file).group(1)\n",
    "            dt = datetime.strptime(datetime_str, \"%Y_%m_%d-%H_%M_%S\")\n",
    "            datetime_files.append((dt, json_file))\n",
    "        except (AttributeError, ValueError):\n",
    "            continue\n",
    "\n",
    "    # Sort the files by datetime\n",
    "    datetime_files = sorted(datetime_files, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    if isinstance(select, int):\n",
    "        # Load the experiment at the specified index\n",
    "        if -len(datetime_files) <= select < len(datetime_files):\n",
    "            file_path = datetime_files[select][1]\n",
    "            with open(file_path, 'r') as f:\n",
    "                return Experiment(json.load(f))\n",
    "        else:\n",
    "            print(f\"Index {select} out of range\")\n",
    "            return None\n",
    "    elif select == \"all\":\n",
    "        # Load all experiments\n",
    "        experiments = []\n",
    "        for _, file_path in datetime_files:\n",
    "            with open(file_path, 'r') as f:\n",
    "                experiments.append(Experiment(json.load(f)))\n",
    "        return experiments\n",
    "    elif select == \"latest\":\n",
    "        # Load the latest experiment\n",
    "        if datetime_files:\n",
    "            latest_file = datetime_files[0][1]\n",
    "            with open(latest_file, 'r') as f:\n",
    "                return Experiment(json.load(f))\n",
    "        else:\n",
    "            print(\"No experiment files found\")\n",
    "            return None\n",
    "    else:\n",
    "        # Load the experiment with the specified datetime string\n",
    "        dt = datetime.strptime(select, \"%Y_%m_%d-%H_%M_%S\")\n",
    "        for file_dt, file_path in datetime_files:\n",
    "            if file_dt == dt:\n",
    "                with open(file_path, 'r') as f:\n",
    "                    return Experiment(json.load(f))\n",
    "        print(f\"No experiment file found with datetime: {select}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "def list_files(dir_path):\n",
    "    return sorted(os.listdir(dir_path), reverse=True)\n",
    "\n",
    "\n",
    "# Plotting\n",
    "\n",
    "colors = ['blue', 'green', 'red', 'cyan', 'magenta', 'yellow', 'black']\n",
    "\n",
    "def plot_avg_mse(*experiments, epistemic=False, ax=None):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    for idx, exp in enumerate(experiments):\n",
    "        if epistemic:\n",
    "            ax.plot(np.arange(1, exp.n_rounds + 1), exp.avg_epistemic_mse, label=exp.algorithm, color=colors[idx])\n",
    "        else:\n",
    "            ax.plot(np.arange(1, exp.n_rounds + 1), exp.avg_mse, label=exp.algorithm, color=colors[idx])\n",
    "\n",
    "    ax.set_xlabel('Round')\n",
    "    ax.set_ylabel(f'Average {\"epistemic \" if epistemic else \"\"}mse')\n",
    "    ax.set_title('Training history')\n",
    "    ax.legend()\n",
    "\n",
    "    if not ax:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_var_mse(*experiments, epistemic=False, ax=None):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    for idx, exp in enumerate(experiments):\n",
    "        if epistemic:\n",
    "            ax.plot(np.arange(1, exp.n_rounds + 1), exp.var_epistemic_mse, label=exp.algorithm, color=colors[idx])\n",
    "        else:\n",
    "            ax.plot(np.arange(1, exp.n_rounds + 1), exp.var_mse, label=exp.algorithm, color=colors[idx])\n",
    "\n",
    "    ax.set_ylim(bottom=0)\n",
    "    ax.set_xlabel('Round')\n",
    "    ax.set_ylabel(f'Variance of {\"epistemic \" if epistemic else \"\"}mse')\n",
    "    ax.set_title('Training history')\n",
    "    ax.legend()\n",
    "\n",
    "    if not ax:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def plot_client_mse_dist(*experiments, ax=None):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    n_clients = experiments[0].n_clients\n",
    "    bar_width = 0.9 / len(experiments)\n",
    "    client_indices = np.arange(n_clients)\n",
    "\n",
    "    for idx, exp in enumerate(experiments):\n",
    "        min_mse_round = np.argmin(exp.avg_epistemic_mse)  # round with minimum avg_mse\n",
    "        client_aleatoric_var_at_min_mse_round = exp.client_aleatoric_var[min_mse_round]\n",
    "        client_epistemic_mse_at_min_mse_round = exp.client_epistemic_mse[min_mse_round]\n",
    "        # sorted_indices = np.argsort(client_epistemic_mse_at_min_mse_round + client_aleatoric_var_at_min_mse_round)\n",
    "        sorted_indices = client_indices\n",
    "\n",
    "        # Create stacked bar by first plotting epistemic mse and then aleatoric variance on top of it\n",
    "        ax.bar(client_indices + idx * bar_width, client_epistemic_mse_at_min_mse_round[sorted_indices], \n",
    "               bar_width, alpha=0.8, label=f'{exp.algorithm} - Epistemic', color=colors[idx])\n",
    "\n",
    "        ax.bar(client_indices + idx * bar_width, client_aleatoric_var_at_min_mse_round[sorted_indices], \n",
    "               bar_width, bottom=client_epistemic_mse_at_min_mse_round[sorted_indices], alpha=0.4, \n",
    "               label=f'{exp.algorithm} - Aleatoric', color=colors[idx])\n",
    "\n",
    "    ax.set_xlabel('Clients')\n",
    "    ax.set_ylabel('Best mse')\n",
    "    ax.set_title('Client mse distribution at minimum avg mse round')\n",
    "    ax.set_xticks(client_indices + bar_width / 2 * len(experiments))\n",
    "    ax.set_xticklabels(sorted_indices.astype(str))\n",
    "    ax.legend()\n",
    "\n",
    "    if not ax:\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "def generate_experiment_summary(*experiments):\n",
    "    info_names = ['algo', 'sim', 'recollect', \n",
    "                  'av_mse', 'v_mse', \n",
    "                  'av_epi_mse', 'v_epi_mse',\n",
    "                  'av_clean_mse', 'v_clean_mse',\n",
    "                  'b_sz', 'lr', 'date']\n",
    "    \n",
    "    info_data = []\n",
    "    for exp in experiments:\n",
    "        ix = np.argmin(exp.avg_epistemic_mse)\n",
    "        info_data.append(\n",
    "            [\n",
    "                exp.algorithm, exp.sim, exp.params['recollection_strategy'],\n",
    "                np.min(exp.avg_mse), exp.var_mse[ix],\n",
    "                exp.avg_epistemic_mse[ix], exp.var_epistemic_mse[ix],\n",
    "                exp.avg_clean_mse[ix], exp.var_clean_mse[ix],\n",
    "                exp.params['batch_size'], exp.params['learning_rate'], exp.date\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    experiments_summary = pd.DataFrame(info_data, columns=info_names)\n",
    "    \n",
    "    experiments_summary.sim = experiments_summary.sim.str.split('/').str[-3:-1]\n",
    "    \n",
    "    experiments_summary.set_index('date', inplace=True)\n",
    "    experiments_summary.sort_index(ascending=False, inplace=True)\n",
    "    \n",
    "    return experiments_summary\n",
    "\n",
    "\n",
    "def summarize_experiments(directory=\"/proj/fair-ai/fair-fl/out\", rows=-1):\n",
    "    # Load all experiments\n",
    "    experiments = load_experiment(\"all\", directory=directory)\n",
    "    display(generate_experiment_summary(*experiments).iloc[:rows])\n",
    "\n",
    "def describe_experiment(*experiments):\n",
    "    experiments_info = generate_experiment_summary(*experiments)\n",
    "    display(experiments_info)\n",
    "    \n",
    "    # Plots\n",
    "    fig = plt.figure(figsize=(14, 14))\n",
    "\n",
    "    # Set up the grid\n",
    "    grid = plt.GridSpec(3, 2, wspace=0.4, hspace=0.3)\n",
    "    \n",
    "    # Add subplots\n",
    "    ax1 = fig.add_subplot(grid[0, 0])  # First row, left\n",
    "    ax2 = fig.add_subplot(grid[0, 1])  # First row, right\n",
    "    ax3 = fig.add_subplot(grid[1, 0])  # Middle row, left\n",
    "    ax4 = fig.add_subplot(grid[1, 1])  # Middle row, right\n",
    "    ax5 = fig.add_subplot(grid[2, :])  # Bottom row, full width\n",
    "    \n",
    "    plot_avg_mse(*experiments, ax=ax1, epistemic=False)\n",
    "    plot_var_mse(*experiments, ax=ax2, epistemic=False)\n",
    "    plot_avg_mse(*experiments, ax=ax3, epistemic=True)\n",
    "    plot_var_mse(*experiments, ax=ax4, epistemic=True)\n",
    "    plot_client_mse_dist(*experiments, ax=ax5)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5737d3-cd8c-4481-9285-9ec2db8e6ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize_experiments(rows=10)\n",
    "summarize_experiments(rows=10, directory=\"/proj/fair-ai/fair-fl/out/bike_hom/nsr_0.2/fedavg/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975ff692-a468-4d45-9d41-eb8d71d9ae35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp = load_experiment(0, directory=\"/proj/fair-ai/fair-fl/out/\")\n",
    "describe_experiment(exp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
